================================================================================
        ARBITRAGELAB COMPLETE REFERENCE - EVERY STRATEGY/SCRIPT
              Through Marcos RLM Framework & MLFinLab Lens
                   For Trading Micro E-Mini Futures
================================================================================

TOTAL FUNCTIONS CATALOGUED: 100+

Every single script with WHO, WHAT, WHEN, WHERE, WHY, HOW from RLM/MLFinLab perspective.
Applied to Micro E-Mini (MES, MNQ, MYM, M2K) trading with 20-iteration framework.

================================================================================
PART 1: COINTEGRATION APPROACH (PAIRS TRADING FOUNDATION)
================================================================================

RESEARCH PAPERS:
- Engle, R.F. and Granger, C.W.J. (1987) "Co-integration and Error Correction: Representation, Estimation, and Testing"
  Link: https://www.jstor.org/stable/1913236
- Johansen, S. (1988) "Statistical Analysis of Cointegration Vectors"
- Vidyamurthy, G. (2004) "Pairs Trading: Quantitative Methods and Analysis"

MLFL FRAMEWORK CONNECTION:
- Cointegration solves the NON-STATIONARITY problem (AFML Chapter 5)
- Creates stationary spreads required for ML (fracdiff alternative)
- Prevents SPURIOUS REGRESSION bias

--------------------------------------------------------------------------------

FILE: cointegration_approach/engle_granger.py
--------------------------------------------------------------------------------

1. EngleGrangerPortfolio class

   WHO: Engle & Granger (Nobel Prize winners, 1987)

   WHAT: Two-step OLS-based cointegration testing and hedge ratio estimation
        - Step 1: Estimate long-run equilibrium relationship via OLS
        - Step 2: Test residuals for unit root (ADF test)
        - Returns hedge ratios and test statistics

   PROBLEM SOLVED (RLM): Creates stationary spread from non-stationary price series.
                         Prevents spurious regression in pairs trading.
                         Identifies long-run equilibrium relationships.

   WHEN TO USE (Micro E-Minis):
   - PRIMARY CHOICE for 2-asset pairs (MES-MNQ, MYM-M2K)
   - When you want the simplest cointegration method
   - For daily or higher frequency data
   - When one asset is clearly the dependent variable

   WHERE IN PIPELINE:
   1. Data: Load MES and MNQ dollar bars
   2. fit(): Estimate hedge ratio β where MES = α + β×MNQ + ε
   3. Check ADF statistic: Is ε stationary?
   4. If p-value < 0.05: Cointegrated, proceed to trading
   5. If p-value >= 0.05: Not cointegrated, discard pair

   WHY (RLM Framework):
   - SPURIOUS REGRESSION BIAS: Non-stationary series can appear correlated by chance
   - Engle-Granger tests ensure TRUE economic relationship
   - Stationary spread = required for mean reversion strategies
   - Connection to AFML Ch 5: fracdiff creates stationarity in single series
     cointegration creates stationarity across SERIES

   HOW (Micro E-Mini Example):
   ```python
   from arbitragelab.cointegration_approach import EngleGrangerPortfolio

   # Load MES and MNQ dollar bars (already did this)
   eg_portfolio = EngleGrangerPortfolio()
   eg_portfolio.fit(price_data=pd.DataFrame({'MES': mes_prices, 'MNQ': mnq_prices}))

   # Check results
   hedge_ratio = eg_portfolio.hedge_ratios  # β for MNQ
   adf_stat = eg_portfolio.adf_statistics  # 99%, 95%, 90% critical values

   # Spread for trading: spread = MES - hedge_ratio × MNQ
   ```

   20-ITERATION RLM APPLICATION:
   ```python
   for i in range(20):
       train_start = i * step_size
       train_end = train_start + 6 * 30  # 6 months training
       test_start = train_end
       test_end = test_start + 1 * 30  # 1 month test

       # Fit on training window
       eg_portfolio.fit(price_data[train_start:train_end])

       # Test cointegration stability
       if eg_portfolio.adf_statistics.loc['statistic_value'][0] < -2.86:  # 5% critical
           # Record pair as valid
           valid_pairs[i] = (MES, MNQ, hedge_ratio)
   ```

   BIASES PREVENTED:
   - Look-ahead bias: Hedge ratio estimated on training data only
   - Sample selection bias: Only trade cointegrated pairs
   - Time-series bias: 20 iterations reveals cointegration stability

   VALIDATION CRITERIA:
   - ADF statistic < -2.86 (5% level) in >= 15/20 iterations
   - Hedge ratio stable (std < 0.1 across iterations)

2. perform_eg_test(residuals)

   WHO: Engle & Granger (via Dickey-Fuller test)

   WHAT: Performs Augmented Dickey-Fuller test on OLS residuals

   PROBLEM SOLVED: Tests whether residuals are stationary (mean-reverting)

   WHEN TO USE: Called automatically by fit(), or for testing custom spreads

   WHY: Determines if pair is truly cointegrated vs spurious correlation

3. get_ols_hedge_ratio(price_data, dependent_variable, add_constant)

   WHAT: Computes OLS regression: y = βX + α

   WHEN TO USE: Internal function, called by fit()

   WHY: Estimates hedge ratio for pairs trading

--------------------------------------------------------------------------------

FILE: cointegration_approach/johansen.py
--------------------------------------------------------------------------------

4. JohansenPortfolio class

   WHO: Johansen (1988), extension of Engle-Granger for multi-asset portfolios

   WHAT: Multivariate cointegration testing using eigenvalue decomposition
        - Tests multiple cointegrating relationships simultaneously
        - Returns multiple hedge ratio vectors (rank r cointegration)
        - More powerful than Engle-Granger for 3+ assets

   PROBLEM SOLVED (RLM): Engle-Granger only handles 2 assets. Johansen handles N assets.
                         Detects multiple independent cointegrating relationships.
                         More statistical power for portfolio construction.

   WHEN TO USE (Micro E-Minis):
   - 3+ asset portfolios (MES-MNQ-MYM-M2K triplet)
   - When Engle-Granger fails but theory suggests cointegration
   - For finding the strongest mean-reverting portfolio among several
   - Sector-based pairs (all micro E-minis together)

   WHERE IN PIPELINE:
   1. Data: Load MES, MNQ, MYM, M2K prices
   2. fit(): Compute eigenvalues and eigenvectors
   3. Check trace statistic and max eigen statistic
   4. Select eigenvector with highest eigenvalue (most mean-reverting)
   5. Normalize hedge ratios

   WHY (RLM Framework):
   - MULTICOLLINEARITY: Micro E-minis highly correlated, need to find true relationships
   - Johansen identifies RANK of cointegration (number of independent relationships)
   - First eigenvector = strongest mean reversion = best trading candidate
   - Connection to AFML Ch 8: PCA-like decomposition but for cointegration

   HOW (Micro E-Mini Example):
   ```python
   from arbitragelab.cointegration_approach import JohansenPortfolio

   # Load 4 micro E-minis
   johansen = JohansenPortfolio()
   johansen.fit(price_data=pd.DataFrame({
       'MES': mes_prices,
       'MNQ': mnq_prices,
       'MYM': mym_prices,
       'M2K': m2k_prices
   }), det_order=0, n_lags=1)

   # First eigenvector = strongest mean-reverting portfolio
   best_hedge_ratios = johansen.hedge_ratios.iloc[0]

   # Check significance
   trace_stat = johansen.johansen_trace_statistic
   eigen_stat = johansen.johansen_eigen_statistic
   ```

   20-ITERATION RLM APPLICATION:
   ```python
   eigenvalues_stability = []

   for i in range(20):
       # Rolling window fit
       johansen.fit(price_data[train_start:train_end])

       # Record largest eigenvalue (strength of cointegration)
       largest_eigenvalue = johansen.johansen_eigen_statistic.loc['eigen_value'].max()
       eigenvalues_stability[i] = largest_eigenvalue

       # Use first hedge ratio vector for trading
       hedge_ratios = johansen.hedge_ratios.iloc[0]
   ```

   VALIDATION CRITERIA:
   - Trace statistic > critical value at 95% level in >= 15/20 iterations
   - First eigenvalue > 0.1 (strong cointegration)
   - Hedge ratios stable across iterations

================================================================================
PART 2: DISTANCE APPROACH (GATEV-GOETZMANN-ROUWENHORST)
================================================================================

RESEARCH PAPER:
- Gatev, E., Goetzmann, W.N., and Rouwenhorst, K.G. (2006) "Pairs Trading: Performance of a Relative-Value Arbitrage Rule"
  Review of Financial Studies, 19(3), 797-827
  Link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=141615

MLFL FRAMEWORK CONNECTION:
- NON-PARAMETRIC approach (no cointegration testing)
- Based on minimizing SSD (sum of squared deviations)
- Alternative to cointegration when tests fail
- Susceptible to spurious regression bias (RLM warning!)

--------------------------------------------------------------------------------

FILE: distance_approach/basic_distance_approach.py
--------------------------------------------------------------------------------

5. DistanceStrategy class

   WHO: Gatev, Goetzmann, Rouwenhorst (2006) - seminal pairs trading paper

   WHAT: Distance-based pairs trading using normalized price distances
        - Normalize prices: (P - min) / (max - min)
        - Find pairs minimizing SSD: Σ(P1_t - P2_t)²
        - Trade when spread diverges by > 2 std deviations
        - Close when spread crosses zero

   PROBLEM SOLVED (RLM): Simplifies pair discovery (no cointegration tests needed).
                         BUT: May find spurious correlations (Marcos warning!)
                         Good for initial screening, then verify with cointegration.

   WHEN TO USE (Micro E-Minis):
   - INITIAL PAIR DISCOVERY: Find candidate pairs
   - When cointegration tests are inconclusive
   - For large universe screening (100+ assets)
   - As FILTER before Engle-Granger verification

   WHERE IN PIPELINE:
   1. Data: Load micro E-mini dollar bars
   2. form_pairs(): Find closest pairs by SSD
   3. Select top N pairs (usually 5-20)
   4. VERIFY with cointegration test
   5. trade_pairs(): Generate signals for verified pairs

   WHY (RLM Framework - CRITICAL WARNING):
   - SAMPLING BIAS: SSD minimization on normalized prices can find spurious patterns
   - Marcos: "Always verify cointegration! Distance alone is insufficient!"
   - Connection to AFML Ch 2: Normalization loses information
   - Recommendation: Use distance for SCREENING only, then verify

   HOW (Micro E-Mini Example):
   ```python
   from arbitragelab.distance_approach import DistanceStrategy

   # Screening phase
   distance = DistanceStrategy()
   distance.form_pairs(
       train_data=price_data[:split_point],
       method='standard',  # or 'zero_crossing' or 'variance'
       num_top=10
   )

   # Get candidate pairs
   pairs = distance.get_pairs()  # Top 10 by SSD

   # VERIFY with cointegration!
   verified_pairs = []
   for pair in pairs:
       eg = EngleGrangerPortfolio()
       eg.fit(price_data[pair])
       if eg.adf_statistics.loc['statistic_value'][0] < -2.86:
           verified_pairs.append(pair)

   # Trade only verified pairs
   distance.trade_pairs(test_data=price_data[split_point:], divergence=2)
   ```

   SELECTION METHODS (key for RLM):
   - 'standard': Sort by SSD (default)
   - 'zero_crossing': Sort by number of zero crossings (more crossings = better)
   - 'variance': Sort by spread variance (higher = more opportunities)

   20-ITERATION RLM APPLICATION:
   ```python
   pair_stability = {}

   for i in range(20):
       train_start = i * step_size
       train_end = train_start + train_length

       # Form pairs on training window
       distance.form_pairs(price_data[train_start:train_end], num_top=20)
       pairs = distance.get_pairs()

       # Verify cointegration
       for pair in pairs:
           if pair not in pair_stability:
               pair_stability[pair] = 0

           eg = EngleGrangerPortfolio()
           eg.fit(price_data[train_start:train_end][list(pair)])
           if eg.adf_statistics.loc['statistic_value'][0] < -2.86:
               pair_stability[pair] += 1

       # Trade in test window
       distance.trade_pairs(price_data[train_end:train_end+test_length])
   ```

   VALIDATION CRITERIA:
   - Pair appears in >= 12/20 iterations (60% stability)
   - Cointegration verified in >= 15/20 iterations
   - Positive Sharpe in >= 15/20 iterations

6. form_pairs(train_data, method, num_top, industry_dict, ...)

   WHAT: Pairs formation using distance minimization

   KEY PARAMETERS:
   - method: 'standard' (SSD), 'zero_crossing' (mean reversion frequency), 'variance' (opportunity)
   - num_top: Number of pairs to select
   - industry_dict: Restrict pairing to same industry (not relevant for micro E-minis)

   WHY (RLM): zero_crossing method preferred - proxies for mean reversion quality

7. trade_pairs(test_data, divergence)

   WHAT: Generate trading signals for formed pairs

   LOGIC:
   - Entry: |spread| > divergence × std (usually 2)
   - Exit: spread crosses zero

   WHY: Simple, robust trading rule

================================================================================
PART 3: COPLA APPROACH (TAIL DEPENDENCE MODELING)
================================================================================

RESEARCH PAPERS:
- Liew, R.Q. and Wu, Y. (2013) "Pairs trading: A copula approach" Journal of Trading
- Xiu, D. "Stochastic arbitrage" (various papers)
- Cherubini, U. et al. (2004) "Copula Methods in Finance"

MLFL FRAMEWORK CONNECTION:
- MODELS TAIL DEPENDENCE (correlation in extreme moves)
- Captures ASYMMETRIC correlations
- Unlike Pearson correlation which assumes linear relationship
- Critical for CRASH PERIODS (Marcos: "Tail risk is what kills strategies!")

--------------------------------------------------------------------------------

FILE: copula_approach/base.py (Copula abstract class)
--------------------------------------------------------------------------------

8. Copula class (abstract base for all copulas)

   WHO: Sklar (1959) - copula theory, applied to finance by Cherubini, Liew, Wu

   WHAT: Models joint distribution of TWO ASSETS separating marginal distributions from dependence
        - C(u,v) = joint CDF
        - u, v = marginal CDFs (pseudo-observations)
        - Captures tail dependence: Correlation during crashes/explosions

   PROBLEM SOLVED (RLM): Pearson correlation misses ASYMMETRIC and TAIL dependence.
                         Pairs can be uncorrelated normally but highly correlated in crashes.
                         Copula captures this - critical for risk management.

   WHEN TO USE (Micro E-Minis):
   - RISK MANAGEMENT: Estimate joint crash probability
   - OPTION VALUATION: Pricing spread options
   - SIGNAL GENERATION: When dependence deviates from normal
   - STRESS TESTING: "What happens in a crash?"

   WHERE IN PIPELINE:
   1. Data: Load MES and MNQ returns
   2. Transform to pseudo-observations: u = F(MES), v = F(MNQ)
   3. fit(): Estimate copula parameter θ from Kendall's tau
   4. get_condi_prob(): P(MES_move | MNQ_move)
   5. Trade when conditional probability is extreme

   WHY (RLM Framework - TAIL RISK):
   - AFML Ch 16: Portfolio optimization requires tail dependence, not just correlation
   - Marcos: "2008 crisis proved correlations are NOT constant"
   - Copulas capture DEPENDENCE STRUCTURE separately from marginals
   - Student-t copula: Symmetric tail dependence (both crashes and rallies)
   - Clayton copula: Lower tail dependence (crashes only)
   - Gumbel copula: Upper tail dependence (rallies only)

   COPULA TYPES (for Micro E-Minis):
   - Gaussian: No tail dependence (underestimates risk)
   - Student-t: Symmetric tail dependence (recommended for equities)
   - Clayton: Lower tail (bearish dependence)
   - Gumbel: Upper tail (bullish dependence)
   - Frank: No tail but asymmetric

   HOW (Micro E-Mini Example):
   ```python
   from arbitragelab.copula_approach import StudentCopula

   # Load MES and MNQ RETURNS (not prices!)
   returns = pd.DataFrame({
       'MES': mes_close.pct_change(),
       'MNQ': mnq_close.pct_change()
   }).dropna()

   # Transform to uniform (pseudo-observations)
   from scipy import stats
   u = stats.rankdata(returns['MES']) / len(returns)
   v = stats.rankdata(returns['MNQ']) / len(returns)

   # Fit Student-t copula
   copula = StudentCopula()
   theta = copula.fit(u, v)  # Estimates from Kendall's tau

   # Get conditional probability
   cond_prob = copula.get_condi_prob(0.1, 0.1)  # P(MES < 10th percentile | MNQ < 10th percentile)

   # Trading: When MES crashes given MNQ crash
   if cond_prob > 0.7:  # High crash dependence
       # Reduce position size (risk management)
       # Or hedge with options
   ```

   20-ITERATION RLM APPLICATION (TAIL RISK STABILITY):
   ```python
   tail_dependence_history = []

   for i in range(20):
       train_returns = returns[train_start:train_end]

       # Fit copula
       u = stats.rankdata(train_returns['MES']) / len(train_returns)
       v = stats.rankdata(train_returns['MNQ']) / len(train_returns)
       copula.fit(u, v)

       # Measure tail dependence at 5% level
       tail_lambda = copula.get_condi_prob(0.05, 0.05)
       tail_dependence_history[i] = tail_lambda

       # Warn if tail dependence increasing
       if tail_lambda > 0.5:
           print(f"Iteration {i}: HIGH CRASH DEPENDENCE! Reduce exposure!")
   ```

   BIASES PREVENTED:
   - NORMALITY BIAS: Gaussian copula underestimates tail risk (2008 mistake!)
   - Use Student-t copula for realistic tail dependence
   - Time-varying tail dependence: 20 iterations reveals regime changes

9. fit(u, v) -> theta_hat

   WHAT: Estimates copula parameter θ from Kendall's tau

   WHY: Kendall's tau is robust to outliers vs Pearson correlation

10. get_condi_prob(u, v) -> P(U<=u | V=v)

   WHAT: Conditional probability - key for trading signals

   USE CASE: "Given MNQ crashes 5%, what's probability MES crashes 5%?"

   WHY (RLM): Dynamic hedge ratios based on conditional probabilities

11. get_cop_density(u, v) -> c(u,v)

   WHAT: Copula density - likelihood of observing (u,v)

   USE CASE: Detecting regime changes in dependence

COPULA SUBTYPES (6 Archimedean + 2 Elliptical):

12. StudentCopula (RECOMMENDED for Micro E-Minis)

    WHAT: Student-t copula with ν degrees of freedom

    PARAMETERS: θ (dependence), ν (tail heaviness)

    WHY RECOMMENDED: Captures symmetric tail dependence (crashes AND rallies)
                     Most realistic for equity indices
                     ν parameter controls tail strength

    MICRO E-MINI USE: MNQ-MES pair with Student-t copula for crash hedging

13. ClaytonCopula

    WHAT: Asymmetric lower-tail copula

    WHEN TO USE: Bearish markets, crash focus only

    MICRO E-MINI USE: MNQ-MES in bear regime (2022-style selloff)

14. GumbelCopula

    WHAT: Asymmetric upper-tail copula

    WHEN TO USE: Bullish markets, rally focus only

    MICRO E-MINI USE: MNQ-MES in bull regime (melt-up scenarios)

15. GaussianCopula (NOT RECOMMENDED)

    WHAT: No tail dependence

    WHY NOT: Underestimates crash risk (2008 mistake!)

    MARCOS WARNING: "Only use for baseline comparison, never for live trading!"

================================================================================
PART 4: OPTIMAL MEAN REVERSION (ORNSTEIN-UHLENBECK MODEL)
================================================================================

RESEARCH PAPERS:
- Leung, T. and Li, X. (2015) "Optimal Mean Reversion Trading: Mathematical Analysis and Practical Applications"
- Bertram, W.K. (2010) "Analytic Solutions for Optimal Statistical Arbitrage Trading" Physica A
- Jurek, J.W. and Yang, H. (2007) "Dynamic Portfolio Selection in Arbitrage" EFA Meetings

MLFL FRAMEWORK CONNECTION:
- Models mean-reverting process as OU: dX = μ(θ - X)dt + σdW
- θ = long-term mean, μ = speed of reversion, σ = volatility
- Solves OPTIMAL STOPPING problem: When to enter/exit?
- Prevents AD-HOC parameter selection bias

--------------------------------------------------------------------------------

FILE: optimal_mean_reversion/ou_model.py
--------------------------------------------------------------------------------

16. OrnsteinUhlenbeck class

    WHO: Tim Leung & Xin Li (2015) - book on optimal mean reversion

    WHAT: Solves optimal double-stopping problem for OU process:
         - Entry level: When to open position?
         - Exit level: When to close position?
         - Stop-loss: Optional constraint
         - Accounts for transaction costs and discount rates

    PROBLEM SOLVED (RLM): AD-HOC PARAMETER SELECTION BIAS.
                          Traders pick arbitrary thresholds (2 std, etc.).
                          Leung-Li derives MATHEMATICALLY OPTIMAL levels.
                          Maximizes expected return with transaction costs.

    WHEN TO USE (Micro E-Minis):
    - AFTER cointegration confirmed
    - For stationary spreads (MES-MNQ, etc.)
    - When you need OPTIMAL entry/exit (not arbitrary thresholds)
    - For risk management with stop-loss

    WHERE IN PIPELINE:
    1. Data: Cointegrated spread (from Engle-Granger or Johansen)
    2. fit(): Estimate OU parameters (θ, μ, σ)
    3. optimal_entry_level(): Compute entry threshold
    4. optimal_liquidation_level(): Compute exit threshold
    5. Trade when spread crosses these levels

    WHY (RLM Framework - MATHEMATICAL OPTIMALITY):
    - AFML Ch 10: Bet sizing requires accounting for transaction costs
    - Leung-Li: CLOSED-FORM solutions (no Monte Carlo needed)
    - Objective: Maximize (expected return - transaction cost) discounted to present
    - Uses stochastic calculus (Itô's lemma, optimal stopping)
    - Result: Entry and exit levels that MAXIMIZE expected Sharpe

    HOW (Micro E-Mini Example):
    ```python
    from arbitragelab.optimal_mean_reversion import OrnsteinUhlenbeck

    # Assume we have cointegrated MES-MNQ spread
    eg = EngleGrangerPortfolio()
    eg.fit(mes_mnq_prices)
    spread = mes_prices - eg.hedge_ratios['MNQ'] * mnq_prices

    # Fit OU model
    ou = OrnsteinUhlenbeck()
    ou.fit(
        data=spread,
        data_frequency='D',  # Daily bars
        discount_rate=0.05,  # 5% annual discount
        transaction_cost=0.0002  # ~$2 per contract (MES ~ $5/point, 1 lot = 2 points)
    )

    # Get optimal levels
    entry_level = ou.optimal_entry_level()  # e.g., -0.8
    exit_level = ou.optimal_liquidation_level()  # e.g., -0.2

    # Trading rule
    if spread < entry_level:
        # Long the spread (long MES, short MNQ)
    elif spread > exit_level:
        # Close position

    # Check half-life
    half_life_days = ou.half_life()
    print(f"Expected mean reversion: {half_life_days:.1f} days")
    ```

    PARAMETERS INTERPRETATION:
    - θ (theta): Long-term mean of spread (usually ~0 for cointegrated pairs)
    - μ (mu): Speed of reversion (higher = faster mean reversion)
    - σ (sigma): Volatility of spread
    - Half-life = ln(2)/μ: Average time to revert halfway to mean

    20-ITERATION RLM APPLICATION:
    ```python
    sharpe_history = []

    for i in range(20):
        # Estimate OU on training window
        ou.fit(spread[train_start:train_end])

        # Record parameters
        mu = ou.mu  # Reversion speed
        theta = ou.theta  # Long-term mean
        sigma = np.sqrt(ou.sigma_square)  # Volatility

        # Check stability
        sharpe_history.append({
            'iteration': i,
            'mu': mu,
            'half_life': ou.half_life(),
            'entry_level': ou.optimal_entry_level(),
            'exit_level': ou.optimal_liquidation_level()
        })

        # Validate: Half-life should be < 30 days for practical trading
        if ou.half_life() > 30:
            print(f"Iteration {i}: WARNING! Half-life too long: {ou.half_life():.1f} days")

    # Check stability across iterations
    mu_std = pd.DataFrame(sharpe_history)['mu'].std()
    if mu_std > 0.5 * pd.DataFrame(sharpe_history)['mu'].mean():
        print("UNSTABLE: Reversion speed varies significantly across iterations")
    ```

    VALIDATION CRITERIA:
    - Half-life < 30 days in >= 15/20 iterations
    - Entry level < 0 (for mean-reversion to positive mean)
    - Exit level > entry level (arbitrage exists)
    - μ > 0.01 (positive reversion speed) in all iterations

    BIASES PREVENTED:
    - AD-HOC SELECTION BIAS: Mathematical optimal, not arbitrary
    - LOOK-AHEAD BIAS: Parameters estimated on training data only
    - OVERFITTING: 20 iterations reveal parameter stability

17. fit(data, data_frequency, discount_rate, transaction_cost, stop_loss)

    WHAT: Fits OU model via maximum likelihood

    KEY PARAMETERS:
    - data_frequency: 'D', 'M', or 'Y' (affects Δt)
    - discount_rate: Annual rate (e.g., 0.05 for 5%)
    - transaction_cost: Per-trade cost (e.g., 0.0002 for MES)
    - stop_loss: Optional stop-loss level

    WHY (RLM): Accounts for TIME VALUE OF MONEY and COSTS (critical!)

18. optimal_entry_level() -> b*

    WHAT: Computes optimal entry threshold (solves F(b*) = b* - c_e)

    INTERPRETATION: Enter when spread < b* (for long) or spread > -b* (for short)

    WHY: Maximizes expected return given transaction cost

19. optimal_liquidation_level() -> d*

    WHAT: Computes optimal exit threshold

    INTERPRETATION: Exit when spread > d* (close long) or spread < -d* (close short)

    WHY: Captures profit before mean reversion reverses

20. half_life() -> ln(2)/μ

    WHAT: Expected time to revert halfway to mean

    USE CASE: Validate that mean reversion is fast enough to trade

    CRITICAL: If half-life > 60 days, not practical for futures trading

21. V(price), V_sl(price)

    WHAT: Expected discounted value of liquidation

    WHY: Used to compute optimal levels (value function in dynamic programming)

--------------------------------------------------------------------------------

FILE: time_series_approach/ou_optimal_threshold_bertram.py
--------------------------------------------------------------------------------

22. OUModelOptimalThresholdBertram class

    WHO: W.K. Bertram (2010) - Physica A

    WHAT: Alternative optimal thresholds for OU process:
         - Closed-form solutions (faster than Leung-Li)
         - Maximizes Sharpe ratio OR expected return
         - Assumes symmetric thresholds (entry at ±a, exit at ±m)

    PROBLEM SOLVED (RLM): Leung-Li requires numerical solving.
                          Bertram provides ANALYTICAL solutions.
                          Faster computation, easier to understand.

    WHEN TO USE (Micro E-Minis):
    - When speed matters (real-time optimization)
    - For comparison with Leung-Li results
    - When you want to maximize Sharpe (not just return)

    WHY (RLM Framework):
    - Sharpe maximization accounts for RISK-ADJUSTED returns
    - Closed-form = fewer numerical issues
    - Good for 20-iteration framework (faster computation)

    HOW (Micro E-Mini Example):
    ```python
    from arbitragelab.time_series_approach import OUModelOptimalThresholdBertram

    # Fit to spread
    bertram = OUModelOptimalThresholdBertram()
    bertram.fit(spread)

    # Get thresholds maximizing Sharpe
    a, m = bertram.get_threshold_by_maximize_sharpe_ratio(
        c=0.0002,  # Transaction cost
        rf=0.02  # Risk-free rate
    )

    # a = entry threshold, m = exit threshold
    # Trade: enter when |spread| > a, exit when |spread| < m
    ```

    VALIDATION: Compare with Leung-Li results - should be similar

================================================================================
PART 5: HEDGE RATIOS (SPREAD CONSTRUCTION)
================================================================================

RESEARCH PAPERS:
- Various: OLS hedge ratio (Engle-Granger)
- Various: Minimum half-life hedge ratio
- Various: Kalman filter hedge ratio

MLFL FRAMEWORK CONNECTION:
- Hedge ratio determines spread STATIONARITY
- Wrong hedge ratio = NON-STATIONARY spread = failed strategy
- Critical for pairs trading

--------------------------------------------------------------------------------

FILE: hedge_ratios/half_life.py
--------------------------------------------------------------------------------

23. get_minimum_hl_hedge_ratio(price_data, dependent_variable)

    WHO: Alternative to OLS hedge ratio

    WHAT: Finds hedge ratio that MINIMIZES half-life of mean reversion
         - Optimizes β to maximize speed of reversion
         - Objective: Minimize |HL(β)|
         - Uses numerical optimization (BFGS)

    PROBLEM SOLVED (RLM): OLS hedge ratio may not minimize half-life.
                          Faster mean reversion = more trades = more profit.
                          Finds β that creates most stationary spread.

    WHEN TO USE (Micro E-Minis):
    - When OLS spread has long half-life (> 30 days)
    - When you want FASTER mean reversion
    - For comparison with OLS hedge ratio

    WHY (RLM Framework):
    - STATIONARITY: Lower half-life = more stationary = better for trading
    - Connection to AFML Ch 5: Creating stationary features
    - Trade-off: May sacrifice some economic interpretation for speed

    HOW (Micro E-Mini Example):
    ```python
    from arbitragelab.hedge_ratios import get_minimum_hl_hedge_ratio

    # Compare OLS vs Min HL hedge ratios
    # OLS (Engle-Granger)
    eg = EngleGrangerPortfolio()
    eg.fit(mes_mnq_prices)
    ols_hedge = eg.hedge_ratios['MNQ'][0]
    ols_spread = mes_prices - ols_hedge * mnq_prices
    ols_hl = get_half_life_of_mean_reversion(ols_spread)

    # Min half-life
    hedge_dict, _, _, _, _ = get_minimum_hl_hedge_ratio(mes_mnq_prices, 'MES')
    min_hl_hedge = hedge_dict['MNQ']
    min_hl_spread = mes_prices - min_hl_hedge * mnq_prices
    min_hl = get_half_life_of_mean_reversion(min_hl_spread)

    print(f"OLS half-life: {ols_hl:.1f} days")
    print(f"Min HL half-life: {min_hl:.1f} days")

    # Use whichever has lower half-life
    if min_hl < ols_hl:
        best_hedge = min_hl_hedge
    else:
        best_hedge = ols_hedge
    ```

    20-ITERATION VALIDATION:
    - Both hedge ratios should produce similar half-lives
    - If min HL is MUCH better, prefer it

================================================================================
PART 6: CODEPENDENCE (NON-LINEAR DEPENDENCE)
================================================================================

RESEARCH PAPER:
- Lopez de Prado, M. "Codependence" Cornell lecture notes
  Link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3512994

MLFL FRAMEWORK CONNECTION:
- AFML Ch 16: Hierarchical Risk Parity requires distance matrix
- Pearson correlation is LINEAR only
- Codependence captures NON-LINEAR dependencies
- Critical for portfolio construction and clustering

--------------------------------------------------------------------------------

FILE: codependence/correlation.py
--------------------------------------------------------------------------------

24. angular_distance(x, y) -> √(0.5 × (1 - ρ))

    WHO: Lopez de Prado (AFML Ch 16)

    WHAT: Metric distance from Pearson correlation

    PROBLEM SOLVED: Pearson correlation is NOT a true metric (violates triangle inequality)
                      Angular distance IS a metric - required for clustering

    WHEN TO USE (Micro E-Minis):
    - Hierarchical clustering for pair selection
    - HRP portfolio construction
    - Distance-based methods

    WHY: Satisfies metric properties required by clustering algorithms

25. absolute_angular_distance(x, y) -> √(0.5 × (1 - |ρ|))

    WHAT: Angular distance using ABSOLUTE correlation

    WHEN TO USE: When you don't care about sign of correlation (just magnitude)

    MICRO E-MINI USE: All micro E-minis are positively correlated, use absolute

26. squared_angular_distance(x, y) -> √(0.5 × (1 - ρ²))

    WHAT: Squared correlation distance

    WHEN TO USE: Emphasizes strong correlations (penalizes weak correlations)

27. distance_correlation(x, y)

    WHAT: Captures LINEAR AND NON-LINEAR dependence

    PROBLEM SOLVED: Pearson misses non-linear relationships

    WHEN TO USE: When you suspect non-linear dependence (options, volatility)

28. kullback_leibler_distance(corr_a, corr_b)

    WHAT: Distance between two correlation matrices

    WHEN TO USE: Detecting regime changes in correlation structure

    20-ITERATION USE: Measure correlation stability across iterations

================================================================================
PART 7: TRADING STRATEGIES (SIGNAL GENERATION)
================================================================================

--------------------------------------------------------------------------------

FILE: trading/z_score.py
--------------------------------------------------------------------------------

29. BollingerBandsTradingRule class

    WHO: E.P. Chan "Algorithmic Trading" (classic pairs trading signal)

    WHAT: Z-score based Bollinger Bands:
         - Entry: |z-score| >= entry_z (e.g., 3)
         - Exit: |z-score| <= exit_z (e.g., entry_z - 1)
         - Long when z < -entry_z, short when z > +entry_z

    PROBLEM SOLVED (RLM): Converts stationary spread to actionable signals.
                          Statistical trading rule based on mean reversion.

    WHEN TO USE (Micro E-Minis):
    - PRIMARY signal generation for mean reversion
    - After cointegration confirmed
    - For any stationary spread (OU process, cointegration, etc.)

    WHERE IN PIPELINE:
    1. Data: Cointegrated spread
    2. Compute rolling z-score: (spread - mean) / std
    3. Entry: |z| >= 3
    4. Exit: |z| <= 0

    WHY (RLM Framework):
    - Mean reversion: Deviations from mean are temporary
    - Z-score: Standardized measure of deviation
    - Connection to AFML Ch 3: Triple barrier uses similar logic

    HOW (Micro E-Mini Example):
    ```python
    from arbitragelab.trading import BollingerBandsTradingRule

    # Initialize
    bb = BollingerBandsTradingRule(
        sma_window=20,  # 20-period moving average
        std_window=20,  # 20-period std deviation
        entry_z_score=3,  # Enter at 3 sigma
        exit_z_score_delta=6  # Exit at 3-6=-3 (cross zero)
    )

    # Process spread
    signals = []
    for spread_value in spread:
        bb.update_spread_value(spread_value)

        # Check entry
        entry_flag, side = bb.check_entry_signal()
        if entry_flag:
            # Open position
            bb.add_trade(start_timestamp, side)

        # Check exit
        closed = bb.update_trades(current_timestamp)

    # Get signals
    target_quantity = bb.get_target_quantity()
    ```

    20-ITERATION RLM APPLICATION:
    ```python
    win_rate_history = []

    for i in range(20):
        # Train: Determine optimal parameters
        # Test: Evaluate performance

        # Try different entry thresholds
        for entry_z in [2, 2.5, 3, 3.5, 4]:
            bb = BollingerBandsTradingRule(
                sma_window=20,
                std_window=20,
                entry_z_score=entry_z,
                exit_z_score_delta=6
            )

            # Backtest on test window
            sharpe = backtest(bb, test_data)

            # Record best
            if sharpe > best_sharpe:
                best_entry_z = entry_z

        win_rate_history.append(best_entry_z)

    # Use most common entry_z across iterations
    optimal_entry_z = mode(win_rate_history)
    ```

================================================================================
PART 8: STOCHASTIC CONTROL APPROACH
================================================================================

RESEARCH PAPER:
- Jurek, J.W. and Yang, H. (2007) "Dynamic Portfolio Selection in Arbitrage"
  Link: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=882536

MLFL FRAMEWORK CONNECTION:
- Solves DYNAMIC PORTFOLIO problem with finite horizon
- Accounts for HORIZON RISK and DIVERGENCE RISK
- Optimal position sizing over time

--------------------------------------------------------------------------------

FILE: stochastic_control_approach/ou_model_jurek.py
--------------------------------------------------------------------------------

30. OUModelJurek class

    WHO: Jurek & Yang (2007) - finite horizon arbitrage

    WHAT: Optimal dynamic position sizing for mean-reverting spread:
         - Accounts for finite trading horizon
         - Non-myopic preferences (look ahead)
         - CRRA utility over terminal wealth
         - Time-varying optimal positions

    PROBLEM SOLVED (RLM): Leung-Li assumes INFINITE horizon.
                          Real traders have finite horizon (contract expiration, etc.).
                          Jurek solves for OPTIMAL positions with horizon risk.

    WHEN TO USE (Micro E-Minis):
    - NEAR CONTRACT EXPIRATION: MES contracts quarterly
    - When you need to CLOSE positions by specific date
    - For optimal position sizing (not just entry/exit)

    WHY (RLM Framework):
    - HORIZON RISK: Spread might not mean revert before deadline
    - Position must account for probability of convergence
    - Connection to AFML Ch 10: Bet sizing for finite horizon

    HOW (Micro E-Mini Example):
    ```python
    from arbitragelab.stochastic_control_approach import OUModelJurek

    # Fit to spread
    jurek = OUModelJurek()
    jurek.fit(
        price_data=spread,
        data_frequency='D',
        T=1/12  # 1 month horizon (until contract expiration)
    )

    # Get optimal position sizes over time
    # Positions decrease as horizon approaches (less time to mean revert)
    positions = jurek.optimal_positions()
    ```

    VALIDATION: Compare with Leung-Li - Jurek should be more conservative near deadline

================================================================================
PART 9: KALMAN FILTER APPROACH
================================================================================

RESEARCH PAPER:
- Elliott, R.J., Aggoun, L. and Moore, J.B. (1995) "Hidden Markov Models: Estimation and Control"
- Various: Kalman filter applications to pairs trading

MLFL FRAMEWORK CONNECTION:
- State-space model for DYNAMIC hedge ratio
- Hedge ratio evolves over time (not static like OLS)
- Accounts for PARAMETER UNCERTAINTY

--------------------------------------------------------------------------------

FILE: other_approaches/kalman_filter.py
--------------------------------------------------------------------------------

31. KalmanFilterStrategy class

    WHO: Kalman (1960) - state-space model, applied to trading by E.P. Chan

    WHAT: Dynamic hedge ratio estimation using Kalman filter:
         - State: Hedge ratio β (hidden/latent)
         - Observation: Price relationship
         - Updates β as new data arrives
         - Provides uncertainty bounds (forecast error std)

    PROBLEM SOLVED (RLM): STATIC hedge ratio (OLS) assumes β is constant.
                          In reality, relationships evolve (regimes, etc.).
                          Kalman filter tracks this evolution.

    WHEN TO USE (Micro E-Minis):
    - When hedge ratio is STABLE but EVOLVING
    - For real-time updating (no refitting needed)
    - When you want uncertainty bounds for risk management

    WHERE IN PIPELINE:
    1. Data: MES and MNQ prices
    2. Initialize Kalman filter
    3. For each new observation: update()
    4. Hedge ratio evolves: β_t = β_{t-1} + K × error
    5. Trade on forecast errors: spread = y - β×x

    WHY (RLM Framework):
    - PARAMETER UNCERTAINTY: Kalman filter provides covariance P
    - ADAPTIVE: Hedge ratio adjusts to new information
    - BAYESIAN: Posterior = Prior × Likelihood
    - Connection to AFML: Online learning vs batch learning

    HOW (Micro E-Mini Example):
    ```python
    from arbitragelab.other_approaches import KalmanFilterStrategy

    # Initialize (tune these via cross-validation)
    kf = KalmanFilterStrategy(
        observation_covariance=0.001,  # Measurement noise
        transition_covariance=1e-4  # Process noise
    )

    # Process data sequentially
    hedge_ratios = []
    spread_std = []

    for mes_price, mnq_price in zip(mes_prices, mnq_prices):
        kf.update(mes_price, mnq_price)
        hedge_ratios.append(kf.hedge_ratios[-1])
        spread_std.append(kf.spread_std_series[-1])

    # Generate signals using forecast errors
    signals = kf.trading_signals(entry_std_score=2, exit_std_score=-2)
    ```

    20-ITERATION RLM APPLICATION:
    ```python
    # Parameter tuning via cross-validation
    for obs_cov in [0.0001, 0.001, 0.01]:
        for trans_cov in [1e-5, 1e-4, 1e-3]:
            kf = KalmanFilterStrategy(obs_cov, trans_cov)

            # Backtest
            sharpe = backtest(kf, train_data)

            # Select best
            if sharpe > best_sharpe:
                best_params = (obs_cov, trans_cov)

    # Validate on test data
    kf = KalmanFilterStrategy(*best_params)
    test_sharpe = backtest(kf, test_data)
    ```

    CRITICAL: Kalman filter is SENSITIVE to parameters - must tune via cross-validation

================================================================================
SUMMARY BY STRATEGY TYPE
================================================================================

+-------------------+---------------------+-------------------+---------------------+
| STRATEGY          | PRIMARY USE         | MICRO E-MINI FIT | RLM BIAS PREVENTED  |
+-------------------+---------------------+-------------------+---------------------+
| Engle-Granger     | 2-asset cointegration| EXCELLENT        | Spurious regression |
| Johansen          | 3+ asset portfolio  | GOOD             | Multicollinearity   |
| Distance          | Initial screening   | GOOD (w/ verify) | Sample selection    |
| Copula            | Tail risk           | EXCELLENT        | Normality bias      |
| OU Model (Leung)  | Optimal entry/exit  | EXCELLENT        | Ad-hoc selection    |
| OU Model (Bertram)| Fast optimization   | GOOD             | Ad-hoc selection    |
| Kalman Filter     | Dynamic hedge ratio | GOOD             | Static assumption   |
| Jurek             | Finite horizon      | GOOD (expiration)| Infinite horizon    |
| Min Half-Life     | Faster reversion    | GOOD             | Slow reversion      |
| Bollinger Bands   | Signal generation   | EXCELLENT        | Ad-hoc thresholds   |
+-------------------+---------------------+-------------------+---------------------+

================================================================================
20-ITERATION RLM FRAMEWORK FOR MICRO E-MINIS
================================================================================

PURPOSE: Reveal stability and prevent overfitting

STEP 1: Define Windows
  - Total data: 5 years of daily MES, MNQ, MYM, M2K
  - Train: 6 months
  - Test: 1 month
  - Step: 1 month
  - Total iterations: 20

STEP 2: For Each Iteration
  ```python
  for i in range(20):
      train_start = i * 20  # 20 trading days per month
      train_end = train_start + 126  # 6 months
      test_start = train_end
      test_end = test_start + 21  # 1 month

      # 1. Pair discovery (Distance approach)
      distance = DistanceStrategy()
      distance.form_pairs(price_data[train_start:train_end], num_top=10)
      pairs = distance.get_pairs()

      # 2. Verify cointegration (Engle-Granger)
      verified = []
      for pair in pairs:
          eg = EngleGrangerPortfolio()
          eg.fit(price_data[train_start:train_end][list(pair)])
          if eg.adf_statistics.loc['statistic_value'][0] < -2.86:
              verified.append(pair)

      # 3. Fit OU model for optimal levels
      ou = OrnsteinUhlenbeck()
      ou.fit(spread[train_start:train_end])
      entry = ou.optimal_entry_level()
      exit = ou.optimal_liquidation_level()

      # 4. Backtest on test period
      for pair in verified:
          signals = generate_signals(pair, entry, exit, test_data)
          sharpe = compute_sharpe(signals)
          results[i] = sharpe
  ```

STEP 3: Validate
  - Mean Sharpe > 0.8
  - Std Sharpe < 0.5 (stable)
  - No degradation (plot vs iteration)
  - Win rate > 55%

STEP 4: Deploy
  - Use median parameters across 20 iterations (robust to outliers)
  - Monitor live performance vs validation range

================================================================================
CRITICAL RLM WARNINGS FOR ARBITRAGELAB
================================================================================

1. DISTANCE APPROACH + NO COINTEGRATION VERIFICATION = SPURIOUS REGRESSION
   - ALWAYS verify with Engle-Granger or Johansen!

2. GAUSSIAN COPULA = TAIL RISK UNDERESTIMATION
   - Use Student-t copula for realistic tail dependence

3. STATIC HEDGE RATIO = PARAMETER STATIONARITY ASSUMPTION
   - Relationships evolve - use Kalman filter or re-fit regularly

4. INFINITE HORIZON ASSUMPTION = UNREALISTIC FOR FUTURES
   - Contracts expire - use Jurek model near expiration

5. AD-HOC THRESHOLDS = OVERFITTING RISK
   - Use Leung-Li or Bertram for MATHEMATICAL OPTIMALITY

6. SINGLE BACKTEST = DATA SNOOPING BIAS
   - Use 20-iteration RLM framework

7. IGNORING TRANSACTION COSTS = INFLATED EXPECTED RETURNS
   - Always include costs in optimization

================================================================================
END OF ARBITRAGELAB COMPLETE REFERENCE
================================================================================
